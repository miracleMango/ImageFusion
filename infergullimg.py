import os
import torch
import numpy as np
from PIL import Image
from torchvision import transforms
from models.model import ImageFusionNetworkWithSourcePE  # å¯¼å…¥ä½ çš„æ¨¡å‹


# -------------------------- é…ç½®å‚æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œåˆ é™¤PATCH_SIZEï¼‰ --------------------------
WEIGHT_PATH = "./saved_models/best_model_loss_0.0712.pth"
TESTSET_ROOT = "./datasets/M3FD_Fusion_test"  # ã€ä¿®æ”¹ä¸ºä½ çš„æµ‹è¯•é›†æ ¹ç›®å½•ã€‘
IR_SUB_DIR = "Ir"  # çº¢å¤–å­ç›®å½•
VIS_SUB_DIR = "Vis"  # å¯è§å…‰å­ç›®å½•
OUTPUT_DIR = "./results/fusion_results_test_color_1.0_fullimg"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)


# -------------------------- æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆåˆ é™¤åˆ†å—/åˆå¹¶å‡½æ•°ï¼Œä¿ç•™å…³é”®transformå’Œåå¤„ç†ï¼‰ --------------------------
# ä¿æŒtransformé€»è¾‘ä¸å˜ï¼ˆä»…åˆ é™¤Resizeï¼Œå› ä¸ºæ•´å›¾æ¨ç†ä¸éœ€è¦å›ºå®šå°ºå¯¸ï¼‰
def get_ir_transform():
    return transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])


def get_vis_transform():
    return transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])


def post_process(tensor, is_ir=False):
    """åå¤„ç†å‡½æ•°ï¼ˆé€‚é…æ•´å›¾è¾“å‡ºï¼Œé€»è¾‘ä¸å˜ï¼‰"""
    tensor = tensor.detach().cpu()
    tensor = (tensor + 1.0) / 2.0  # åå½’ä¸€åŒ–åˆ°[0,1]
    tensor = torch.clamp(tensor, 0.0, 1.0)  # é˜²æ­¢æ•°å€¼æº¢å‡º

    if is_ir:
        img = tensor.squeeze(0).numpy()
        img = (img * 255).astype(np.uint8)
        return Image.fromarray(img, mode="L")
    else:
        img = tensor.permute(1, 2, 0).numpy()  # (C,H,W) -> (H,W,C)
        img = (img * 255).astype(np.uint8)
        return Image.fromarray(img)


# -------------------------- å•å¼ å›¾ç‰‡å¯¹æ¨ç†å‡½æ•°ï¼ˆæ•´å›¾æ¨ç†ç‰ˆæœ¬ï¼‰ --------------------------
def infer_single_pair(ir_path, vis_path, output_dir):
    basename = os.path.basename(ir_path)
    fusion_path = os.path.join(output_dir, basename)  # è¾“å‡ºæ–‡ä»¶åä¸è¾“å…¥ä¿æŒä¸€è‡´

    # åŠ è½½æ¨¡å‹ï¼ˆå…¨å±€ä»…åŠ è½½ä¸€æ¬¡ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
    global model
    if "model" not in globals():
        model = ImageFusionNetworkWithSourcePE(
            vis_img_channels=3,
            ir_img_channels=1,
            feature_channels=64,
            num_heads=16,
            use_position_encoding=True
        ).to(DEVICE)
        
        # åŠ è½½æ¨¡å‹æƒé‡ï¼ˆå…¼å®¹å®Œæ•´checkpointæˆ–ä»…state_dictï¼‰
        checkpoint = torch.load(WEIGHT_PATH, map_location=DEVICE, weights_only=False)
        if "model_state_dict" in checkpoint:
            model.load_state_dict(checkpoint["model_state_dict"])
        else:
            model.load_state_dict(checkpoint)
        
        model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
        print(f"âœ… æ¨¡å‹å·²åŠ è½½ï¼Œå¼€å§‹å¤„ç†å›¾ç‰‡å¯¹ï¼š{basename}")

    # 1. è¯»å–æ•´å¼ å›¾ç‰‡ï¼ˆä¸åšåˆ†å—ï¼‰
    ir_img_full = Image.open(ir_path).convert("L")  # çº¢å¤–å›¾è½¬å•é€šé“
    vis_img_full = Image.open(vis_path).convert("RGB")  # å¯è§å…‰å›¾è½¬ä¸‰é€šé“

    # 2. åŠ è½½transformå¹¶é¢„å¤„ç†æ•´å¼ å›¾ç‰‡
    ir_transform = get_ir_transform()
    vis_transform = get_vis_transform()
    
    ir_tensor = ir_transform(ir_img_full).unsqueeze(0).to(DEVICE)  # (1,1,H,W)
    vis_tensor = vis_transform(vis_img_full).unsqueeze(0).to(DEVICE)  # (1,3,H,W)

    # 3. æ•´å›¾æ¨ç†ï¼ˆæ— patchå¾ªç¯ï¼‰
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœæ˜¾å­˜
        outputs = model(ir_tensor, vis_tensor)
        fusion_tensor = outputs["img_fusion_pred"][0]  # å–batchä¸­ç¬¬ä¸€ä¸ªï¼ˆä»…å•å¼ ï¼‰

    # 4. åå¤„ç†æ•´å¼ èåˆå›¾
    full_fusion = post_process(fusion_tensor, is_ir=False)

    # 5. ä¿å­˜æ•´å›¾èåˆç»“æœ
    full_fusion.save(fusion_path)
    
    return basename, fusion_path


# -------------------------- æ‰¹é‡å¤„ç†æµ‹è¯•é›†ï¼ˆé€»è¾‘ä¸å˜ï¼Œä»…è°ƒç”¨æ•´å›¾æ¨ç†å‡½æ•°ï¼‰ --------------------------
def batch_process_testset():
    ir_dir = os.path.join(TESTSET_ROOT, IR_SUB_DIR)
    vis_dir = os.path.join(TESTSET_ROOT, VIS_SUB_DIR)
    
    # è·å–åŒ¹é…çš„æ–‡ä»¶åï¼ˆçº¢å¤–å’Œå¯è§å…‰æ–‡ä»¶åéœ€ä¸€è‡´ï¼‰
    ir_filenames = [f for f in os.listdir(ir_dir) if f.endswith((".png", ".jpg", ".jpeg"))]
    vis_filenames = [f for f in os.listdir(vis_dir) if f.endswith((".png", ".jpg", ".jpeg"))]
    common_filenames = list(set(ir_filenames) & set(vis_filenames))

    if not common_filenames:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„çº¢å¤–-å¯è§å…‰å›¾ç‰‡å¯¹ï¼è¯·æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸€è‡´ã€‚")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(common_filenames)} å¯¹åŒ¹é…çš„å›¾ç‰‡ï¼Œå¼€å§‹æ‰¹é‡æ•´å›¾æ¨ç†...")

    for idx, filename in enumerate(common_filenames, 1):
        ir_path = os.path.join(ir_dir, filename)
        vis_path = os.path.join(vis_dir, filename)
        basename, fusion_path = infer_single_pair(ir_path, vis_path, OUTPUT_DIR)
        print(f"ğŸ”§ å·²å®Œæˆ {idx}/{len(common_filenames)}ï¼š{basename}ï¼Œèåˆå›¾ä¿å­˜è‡³ï¼š{fusion_path}")

    print(f"\nâœ… æ‰¹é‡æ•´å›¾æ¨ç†å®Œæˆï¼")
    print(f"   - æ‰€æœ‰èåˆå›¾ä¿å­˜è‡³ï¼š{os.path.abspath(OUTPUT_DIR)}")


# -------------------------- è¿è¡Œ --------------------------
if __name__ == "__main__":
    batch_process_testset()
